{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data mining"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We access the data given by the professor and store them in a compact dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run scripts/data_collection_setup.py\n",
    "\n",
    "directory = 'data/raw'\n",
    "df = pd.DataFrame()\n",
    "for filename in os.listdir(directory):\n",
    "\n",
    "    dataset = pd.read_csv(directory + '/' + filename)\n",
    "    dataset = dataset[[\"Datetime\", \"Tweet Id\", \"original_text\", \"geo\"]].dropna(subset=[\"geo\"])\n",
    "    dataset[\"geo\"] = dataset[\"geo\"].apply(lambda x: x[x.find('place_id')+12:x.find('place_id')+12+16])\n",
    "\n",
    "    df = pd.concat([df, dataset], ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We request geolocalization data to the Twitter API using \"place_id\" and store the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = get_access_token()\n",
    "\n",
    "update_gs = pd.Series()\n",
    "for x, y in zip(range(0, len(df[\"geo\"]), 50), range(50, len(df[\"geo\"]), 50)):\n",
    "    geo_series = df[\"geo\"][x:y].apply(get_geo_data, args=(access_token,))\n",
    "    update_gs = pd.concat([update_gs, geo_series])\n",
    "    time.sleep(60*17)\n",
    "\n",
    "update_gs.to_csv(\"data/update_gs.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build the dataset with only Nigerian tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv(\"data/update_gs.csv\").squeeze()\n",
    "\n",
    "y = y.apply(ast.literal_eval)\n",
    "y = y.apply(pd.Series)\n",
    "y = y[['id', 'name', 'place_type', 'full_name', 'country', 'bounding_box', 'centroid']]\n",
    "\n",
    "df.rename(columns = {'geo' : 'id'}, inplace=True)\n",
    "tweet_df = df.iloc[:3550].merge(y, right_index=True, left_index=True, validate=\"1:1\")\n",
    "tweet_df = tweet_df[tweet_df.country=='Nigeria'].sort_values(by=\"Datetime\")\n",
    "tweet_df.to_csv('data/tweet_df.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We request rainfall data from weather API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "regions = [\n",
    "    'calabar',\n",
    "    'warri',\n",
    "    'benin', \n",
    "    'lagos',\n",
    "    'enugu',\n",
    "    'ikeja',\n",
    "    'ondo',\n",
    "    'ibadan',\n",
    "    'oshogbo',  \n",
    "    'lokoja',\n",
    "    'bida',\n",
    "    'yola', \n",
    "    'minna',\n",
    "    'jos',\n",
    "    'bauchi',\n",
    "    'kaduna',\n",
    "    'yelwa',\n",
    "    'zaria',\n",
    "    'maiduguri',\n",
    "    'kano',\n",
    "    'gusau',\n",
    "    'nguru',\n",
    "    'sokoto',\n",
    "    'katsina'\n",
    "]\n",
    "\n",
    "months = ['2022-{:02d}-08'.format(x) for x in range(1, 12)]\n",
    "rain_df = pd.Series(tuple(product(months, regions)), index=tuple(product(months, regions))).unstack()\n",
    "rain_df = rain_df.applymap(rain_request)\n",
    "rain_df.to_csv('data/rain_df_4.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get timeseries for daily average precipitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_df = pd.read_csv('data/rain_df_2.csv', index_col=0)\n",
    "rain_df = rain_df.applymap(ast.literal_eval)\n",
    "rain_df.index = pd.to_datetime(rain_df.index)\n",
    "rain_df = rain_df.resample('D').fillna('ffill')\n",
    "\n",
    "for region in rain_df.columns:\n",
    "    for date in rain_df.index:\n",
    "        rain_df.loc[date, region] = dict_selection(rain_df.loc[date, region], date)\n",
    "\n",
    "rain_df = rain_df.dropna()\n",
    "rain_df.to_csv('data/rain_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "67783390838d2e02912aac04d405c75735cc05868bfeaabbe6ec2bbdb2e2542d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
