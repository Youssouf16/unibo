{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading files and preparing the tweets (pre-processing is applied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rober\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\rober\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\rober\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%run scripts/pre_processing.py\n",
    "df = pd.read_csv('data/tweet_df_class.csv', index_col='Datetime').drop('Unnamed: 0', axis=1)\n",
    "tweets_text = df.original_text\n",
    "prep_tweets = tweets_text.apply(pre_processing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating two datasets: one of \"malaria tweets\" and one of \"not malaria tweets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['preproc'] = prep_tweets\n",
    "nodup_df = df.drop_duplicates(subset='original_text')\n",
    "tmp_tweets = nodup_df[['preproc', 'class']].reset_index(drop=True)\n",
    "cases_tweets = tmp_tweets[tmp_tweets['class']==1]\n",
    "not_cases_tweets = tmp_tweets[tmp_tweets['class']==0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a series with the most frequently used tokens in \"malaria tweets\" and their frequencies\n",
    "(bag of words is used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, bow_matrix = bag_of_words(cases_tweets.preproc)\n",
    "bow_df = pd.DataFrame(bow_matrix, columns = vocab)\n",
    "common_words = bow_df.sum(axis=0).sort_values()[-286:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the dataframe with oversampled tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the labeled common words dataframe\n",
    "words_df = pd.read_csv('data/common_words.csv')\n",
    "\n",
    "#creating a dictionary with key = part of sentence and value = dataframe of tokens related to that part of sentence\n",
    "#a is adjective, n is noun, v is verb and r is \"other\"\n",
    "words_split = {}\n",
    "for i, words in words_df.groupby('part'):\n",
    "    words.freq = words.freq/sum(words.freq) #you may change words.freq with the frequency of only test data tokens\n",
    "    words_split.update({str(i) : words.drop('part', axis=1)})\n",
    "\n",
    "#absolute frequencies of each category\n",
    "ss = words_df.groupby('part').sum()\n",
    "\n",
    "#creating a series of uncommon words (index) and their relative frequencies \n",
    "noise_words = bow_df.sum(axis=0).sort_values()[:-286] #here too you can use noises from only test data tokens\n",
    "noise_words /= sum(noise_words)\n",
    "\n",
    "#generating fake tweets from the oversampling function\n",
    "\n",
    "def fake_tweetter(n):\n",
    "\n",
    "    fake_tweets = pd.DataFrame(np.array([oversampler(words_split, noise_words) for i in range(n)]).T,\n",
    "            columns = ['preproc'])\n",
    "    fake_tweets.preproc = fake_tweets.preproc.str.split()\n",
    "    fake_tweets.insert(1, 'class', 1)\n",
    "\n",
    "    return fake_tweets\n",
    "\n",
    "#tweets with oversampling\n",
    "z = 1000\n",
    "oversampled_tweets = pd.concat([tmp_tweets, fake_tweetter(z)]).reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "\n",
    "# slitting variables with target and dependent variables\n",
    "X = oversampled_tweets['preproc']\n",
    "y = oversampled_tweets['class']\n",
    "\n",
    "#bag of words\n",
    "vocab, X = bag_of_words(X)\n",
    "\n",
    "# Splitting into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[:-z], y[:-z], test_size=0.3)\n",
    "\n",
    "#oversampling\n",
    "fakes = np.c_[X[-z:], y[-z:]]\n",
    "i_fakes = np.random.choice(range(z), len(y_train[y_train==0])-len(y_train[y_train==1]), replace=False)\n",
    "r_fakes = fakes[i_fakes]\n",
    "X_train = np.r_[X_train, r_fakes[:, :-1]]\n",
    "y_train = np.r_[y_train, r_fakes[:, -1]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.8084291187739464\n"
     ]
    }
   ],
   "source": [
    "# training random forest classifier \n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# score of the test\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(\"Accuracy : \", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SVC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rober\\Desktop\\python_work\\project207\\classification.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rober/Desktop/python_work/project207/classification.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# training svm classifier SVM\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/rober/Desktop/python_work/project207/classification.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m clf \u001b[39m=\u001b[39m SVC(kernel\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlinear\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rober/Desktop/python_work/project207/classification.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m clf\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rober/Desktop/python_work/project207/classification.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# accuracy of the classifier\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SVC' is not defined"
     ]
    }
   ],
   "source": [
    "# training svm classifier SVM\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# accuracy of the classifier\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "\n",
    "# accuracy\n",
    "print(\"Accuracy : \", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGB classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert format to DMatrix for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Definig parameters for XGBoost\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'max_depth': 5,\n",
    "    'eta': 0.1,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'min_child_weight': 5,\n",
    "    'silent': 0,\n",
    "}\n",
    "\n",
    "# training XGBoost model\n",
    "bst = xgb.train(params, dtrain, num_boost_round=100)\n",
    "\n",
    "# Faire des prédictions sur le jeu de test\n",
    "y_pred = bst.predict(dtest)\n",
    "\n",
    "accuracy = bst.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1870"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to do k-folds crossvalidation with oversampling and four metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_score(model, X, y, k):\n",
    "\n",
    "    #create k-folds (test)\n",
    "    folds = []\n",
    "    real = np.c_[X[:-z], y[:-z]]\n",
    "    for kf in range(k):\n",
    "        i_real = np.random.choice(range(real.shape[0]),int(X[:-z].shape[0]/k),replace=False)\n",
    "        r_real = real[i_real]\n",
    "        folds.append(r_real)\n",
    "        \n",
    "        #removing selected tweets\n",
    "        real = np.delete(real, i_real, axis=0)\n",
    "\n",
    "    #running models\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    F1s = []\n",
    "    for i in range(k):\n",
    "        test = folds[i]\n",
    "        train = np.vstack([folds[j] for j in range(k) if j!=i])\n",
    "        \n",
    "        #oversampling\n",
    "        fakes = np.c_[X[-z:], y[-z:]]\n",
    "        i_fakes = np.random.choice(range(z), len(train[:, -1][train[:, -1]==0])-len(train[:, -1][train[:, -1]==1]), replace=False)\n",
    "        r_fakes = fakes[i_fakes]\n",
    "        train = np.r_[train, r_fakes]\n",
    "        \n",
    "        #models\n",
    "        model.fit(train[:, :-1], train[:, -1])\n",
    "        pred = model.predict(test[:, :-1])\n",
    "\n",
    "        #metrics\n",
    "        precision = precision_score(test[:, -1], pred)\n",
    "        recall = recall_score(test[:, -1], pred)\n",
    "        accuracy = accuracy_score(test[:, -1], pred)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        accuracies.append(accuracy)\n",
    "        F1s.append((2*recall*precision)/(recall+precision))\n",
    "\n",
    "\n",
    "    return np.array(accuracies), np.array(precisions), np.array(recalls), np.array(F1s)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest with cross-correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores :  [0.81481481 0.69444444 0.7962963  0.78703704 0.78703704 0.75925926\n",
      " 0.76851852 0.74074074]\n",
      "Accuracy : 0.77 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "# random forest classifier with cross validation\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "scores = cross_val_score(clf, X[:-z], y[:-z], cv=8)\n",
    "accuracies, precisions, recalls, F1s = cross_score(clf, X, y, 8)\n",
    "\n",
    "# score of the rfcv test\n",
    "print(\"Scores : \", accuracies)\n",
    "\n",
    "# Afficher la moyenne et l'écart-type des scores\n",
    "print(\"Accuracy : %0.2f (+/- %0.2f)\" % (accuracies.mean(), accuracies.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM classifier with cross-correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training SVM with cv\n",
    "clf = SVC(kernel='linear')\n",
    "scores = cross_val_score(clf, X[:-250], y[:-250], cv=5)\n",
    "\n",
    "# scores\n",
    "print(\"Scores : \", scores)\n",
    "\n",
    "# scrores with sd\n",
    "print(\"Accuracy : %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "67783390838d2e02912aac04d405c75735cc05868bfeaabbe6ec2bbdb2e2542d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
